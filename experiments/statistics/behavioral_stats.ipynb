{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb489560",
   "metadata": {},
   "source": [
    "This notebook is for taking statistics over thousands of runs, in order to analyze which maze features (e.g. distance to cheese) tend to affect decision-making. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4881a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded https://nerdsniper.net/mats/episode_stats_data.tgz\n",
      "Already downloaded https://nerdsniper.net/mats/model_rand_region_5.pth\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import procgen_tools\n",
    "except ImportError:\n",
    "    get_ipython().run_line_magic(\n",
    "        magic_name=\"pip\",\n",
    "        line=\"install -U git+https://github.com/ulissemini/procgen-tools\",\n",
    "    )\n",
    "\n",
    "from procgen_tools.utils import setup\n",
    "\n",
    "setup(dl_stats=True)  # create directory structure and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c479b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from procgen import ProcgenGym3Env\n",
    "from procgen_tools import maze\n",
    "from procgen_tools.models import load_policy\n",
    "from procgen_tools.metrics import metrics, decision_square \n",
    "from procgen_tools.data_utils import load_episode\n",
    "\n",
    "from IPython import display\n",
    "from glob import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random \n",
    "from typing import List, Tuple, Any, Dict, Union, Optional\n",
    "\n",
    "import prettytable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff6529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle text formatting\n",
    "def bold_text(text: str):\n",
    "    return \"\\033[1m\" + text + \"\\033[0m\"\n",
    "\n",
    "\n",
    "# In the \"Understanding and controlling a maze-solving policy network\" post, we claimed that the following attributes are important. We'll often bold them in the text.\n",
    "claimed_attributes = [\n",
    "    \"steps_between_cheese_decision_square\",\n",
    "    \"euc_dist_cheese_decision_square\",\n",
    "    \"euc_dist_cheese_top_right\",\n",
    "    \"euc_dist_decision_square_5x5\",\n",
    "]\n",
    "\n",
    "\n",
    "def english_attr(attr: str) -> str:\n",
    "    \"\"\"Maps an attribute to its English name.\"\"\"\n",
    "    if attr == \"steps_between_cheese_5x5\":\n",
    "        return \"Steps between cheese and top-right 5x5\"\n",
    "    elif attr == \"euc_dist_cheese_5x5\":\n",
    "        return \"Euclidean distance between cheese and top-right 5x5\"\n",
    "    elif attr == \"steps_between_decision_square_5x5\":\n",
    "        return \"Steps between decision square and top-right 5x5\"\n",
    "    elif attr == \"euc_dist_decision_square_5x5\":\n",
    "        return \"Euclidean distance between decision square and top-right 5x5\"\n",
    "    elif attr == \"steps_between_cheese_top_right\":\n",
    "        return \"Steps between cheese and top right square\"\n",
    "    elif attr == \"euc_dist_cheese_top_right\":\n",
    "        return \"Euclidean distance between cheese and top right square\"\n",
    "    elif attr == \"steps_between_decision_square_top_right\":\n",
    "        return \"Steps between decision square and top right square\"\n",
    "    elif attr == \"euc_dist_decision_square_top_right\":\n",
    "        return (\n",
    "            \"Euclidean distance between decision square and top right square\"\n",
    "        )\n",
    "    elif attr == \"steps_between_cheese_decision_square\":\n",
    "        return \"Steps between cheese and decision square\"\n",
    "    elif attr == \"euc_dist_cheese_decision_square\":\n",
    "        return \"Euclidean distance between cheese and decision square\"\n",
    "    elif attr == \"cheese_coord_norm\":\n",
    "        return \"Norm of cheese coordinate\"\n",
    "    elif attr == \"taxi_dist_cheese_decision_square\":\n",
    "        return \"Taxicab distance between cheese and decision square\"\n",
    "    elif attr == \"taxi_dist_cheese_top_right\":\n",
    "        return \"Taxicab distance between cheese and top right square\"\n",
    "    elif attr == \"taxi_dist_decision_square_top_right\":\n",
    "        return \"Taxicab distance between decision square and top right square\"\n",
    "    elif attr == \"taxi_dist_cheese_5x5\":\n",
    "        return \"Taxicab distance between cheese and top-right 5x5\"\n",
    "    elif attr == \"taxi_dist_decision_square_5x5\":\n",
    "        return \"Taxicab distance between decision square and top-right 5x5\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown attribute {attr}\")\n",
    "\n",
    "\n",
    "def format_attr(attr: str):\n",
    "    attr_str = english_attr(attr)\n",
    "    return bold_text(attr_str) if attr in claimed_attributes else attr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04235c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 163 runs\n"
     ]
    }
   ],
   "source": [
    "model_name: str = \"model_rand_region_1\"\n",
    "files = glob(f\"experiments/statistics/data/{model_name}/*.pkl\")\n",
    "runs = []\n",
    "for f in files:\n",
    "    try:\n",
    "        runs.append(load_episode(f, load_venv=False))\n",
    "    except (AssertionError, KeyError) as e:\n",
    "        print(f\"Malformed file {f}: {e}\")\n",
    "        os.remove(f)\n",
    "\n",
    "print(f\"Loaded {len(runs)} runs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc216e38",
   "metadata": {},
   "source": [
    "We only consider mazes which have decision squares, since these are the\n",
    "mazes where the policy confronts a nontrivial choice (between the cheese\n",
    "and the top-right corner). Furthermore, we check that the cheese\n",
    "isn't in the top-right 5x5 corner of the reachable maze. This ensures we\n",
    "aren't sampling from the training distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "151864ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:09<00:00, 16.56it/s]\n"
     ]
    }
   ],
   "source": [
    "recorded_metrics = defaultdict(list)\n",
    "recorded_runs = []\n",
    "got_cheese = []\n",
    "for run in tqdm(runs):\n",
    "    g = run.grid()\n",
    "    if decision_square(g) is None or (g[-5:, -5:] == maze.CHEESE).any():\n",
    "        continue\n",
    "    for name, metric in metrics.items():\n",
    "        recorded_metrics[name].append(metric(g))\n",
    "    got_cheese.append(float(run.got_cheese))\n",
    "    recorded_runs.append(run)\n",
    "\n",
    "runs = recorded_runs\n",
    "del recorded_runs\n",
    "got_cheese = np.array(got_cheese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6cb7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to turn the metrics into a dataframe, so we have to convert them to numpy arrays\n",
    "for name, metric in recorded_metrics.items():\n",
    "    recorded_metrics[name] = np.array(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a207f4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(get cheese | decision square, cheese not in top 5x5) = 0.000\n"
     ]
    }
   ],
   "source": [
    "prob = sum(got_cheese) / len(got_cheese)\n",
    "print(f\"P(get cheese | decision square, cheese not in top 5x5) = {prob:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f00443e8",
   "metadata": {},
   "source": [
    "We can explore the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9338e2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06aff4788cb45279f533f34034d390a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='metric', options=('euc_dist_cheese_decision_square', 'taxi_dist_ch…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a plotly histogram, where you select which metric to display using a dropdown menu\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact\n",
    "import math\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "\n",
    "\n",
    "@interact\n",
    "def show_histogram(metric=list(recorded_metrics.keys())):\n",
    "    \"\"\"Show a histogram of the metric on this dataset.\"\"\"\n",
    "    fig.data = []\n",
    "\n",
    "    # Add a trace to fig\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=recorded_metrics[metric], histnorm=\"probability density\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Set the title\n",
    "    fig.update_layout(title_text=f\"Histogram of {english_attr(metric)}\")\n",
    "    # Set y axis label to probability density\n",
    "    fig.update_yaxes(title_text=\"Probability density\")\n",
    "    fig.update_xaxes(title_text=english_attr(metric))\n",
    "\n",
    "    # Automatically display updates to fig without having to call fig.show()\n",
    "    display.display(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "560a4e90",
   "metadata": {},
   "source": [
    "And see how the data points relate to each other. Many exhibit natural correlations from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f18bc057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a029ae95685248aebc852a8357aff182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='metric1', options=('euc_dist_cheese_decision_square', 'taxi_dist_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Dropdown, Checkbox\n",
    "\n",
    "scatter_distances_fig = go.FigureWidget()\n",
    "\n",
    "\n",
    "# Make plotly scatterplot comparing two metrics, to check for collinearity\n",
    "@interact\n",
    "def show_scatter(\n",
    "    metric1=Dropdown(\n",
    "        options=list(recorded_metrics.keys()),\n",
    "        value=\"euc_dist_cheese_decision_square\",\n",
    "    ),\n",
    "    metric2=Dropdown(\n",
    "        options=list(recorded_metrics.keys()),\n",
    "        value=\"steps_between_cheese_decision_square\",\n",
    "    ),\n",
    "):\n",
    "    \"\"\"Show a scatterplot of two metrics on this dataset.\"\"\"\n",
    "    data = pd.DataFrame(recorded_metrics)\n",
    "\n",
    "    # Plot the scatterplot\n",
    "    scatter_distances_fig.data = []\n",
    "    scatter_distances_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=data[metric1], y=data[metric2], mode=\"markers\", name=\"runs\"\n",
    "        )\n",
    "    )\n",
    "    scatter_distances_fig.update_layout(\n",
    "        title_text=f\"{english_attr(metric1)} vs {english_attr(metric2)}\"\n",
    "    )\n",
    "    scatter_distances_fig.update_xaxes(title_text=english_attr(metric1))\n",
    "    scatter_distances_fig.update_yaxes(title_text=english_attr(metric2))\n",
    "    display.display(scatter_distances_fig)\n",
    "\n",
    "    # Draw a line of best fit\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "        data[metric1], data[metric2]\n",
    "    )\n",
    "    scatter_distances_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=data[metric1],\n",
    "            y=slope * data[metric1] + intercept,\n",
    "            mode=\"lines\",\n",
    "            name=\"best fit\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Hide the legend\n",
    "    scatter_distances_fig.update_layout(showlegend=False)\n",
    "\n",
    "    # Print the correlation coefficient\n",
    "    print(f\"Correlation: {np.corrcoef(data[metric1], data[metric2])[0,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68d758e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "(%{x}, %{y}) = %{z:.3f} <extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           1,
           0.9752025945457043,
           0.7064839380841728,
           0.6017644964250538,
           0.7134342426276332,
           0.6067383985416013,
           0.46068237981420174,
           0.46585885054303944,
           0.38188312962464477,
           0.5563515123859162,
           0.3487487076374941,
           0.7402125319644,
           0.656942241125295,
           0.4587898217739536,
           0.48152185889055094,
           0.3462600733389088
          ],
          [
           0.9752025945457043,
           1,
           0.7655148768298249,
           0.5864223273153959,
           0.6706893749708235,
           0.5579345768512534,
           0.4318234268097244,
           0.43627981535159316,
           0.33903331149236665,
           0.5473200590841563,
           0.3203965352301584,
           0.6992338468349271,
           0.6118462879024481,
           0.42950313862274075,
           0.45322697884865537,
           0.3983333401572341
          ],
          [
           0.7064839380841728,
           0.7655148768298249,
           1,
           0.4927383892163907,
           0.3821404661548813,
           0.3166569638943136,
           0.22147951388591205,
           0.20997526322350027,
           0.13152453890928784,
           0.5364858694767576,
           0.1721659288555613,
           0.40094535571188034,
           0.3348713444846886,
           0.2427745663262212,
           0.2613741202431961,
           0.5015520373215445
          ],
          [
           0.6017644964250539,
           0.5864223273153959,
           0.4927383892163906,
           1,
           0.791690651103653,
           0.8203541509893587,
           0.9058140248896379,
           0.8981025929346332,
           0.9274253826568852,
           0.9625967331790322,
           0.9111475170492643,
           0.7744145041398566,
           0.8210524945332096,
           0.9163311823767482,
           0.920077845565032,
           -0.14826609459177875
          ],
          [
           0.7134342426276333,
           0.6706893749708235,
           0.38214046615488134,
           0.791690651103653,
           1,
           0.9687659056163319,
           0.7290158040730288,
           0.7152957660112031,
           0.7376535095353034,
           0.7037495480222489,
           0.6362989086685519,
           0.9939541857270471,
           0.9863802647365705,
           0.7324947421319666,
           0.7128581331445778,
           -0.02625436681532069
          ],
          [
           0.6067383985416013,
           0.5579345768512534,
           0.3166569638943135,
           0.8203541509893587,
           0.9687659056163319,
           0.9999999999999999,
           0.7963927761453881,
           0.7846097336052781,
           0.7984524462689734,
           0.751285887440661,
           0.7244485841419488,
           0.9380792965918818,
           0.9807847284076574,
           0.7973863424970653,
           0.7813797870054365,
           -0.2155124909581689
          ],
          [
           0.46068237981420174,
           0.4318234268097244,
           0.22147951388591203,
           0.9058140248896379,
           0.7290158040730288,
           0.7963927761453881,
           1,
           0.9978063945212479,
           0.9367169117551477,
           0.8651423238514423,
           0.9375184671839226,
           0.6930623830954393,
           0.7728802314687854,
           0.9970874898103477,
           0.9950106215451961,
           -0.38330558504857704
          ],
          [
           0.46585885054303944,
           0.43627981535159316,
           0.2099752632235003,
           0.8981025929346332,
           0.7152957660112031,
           0.7846097336052781,
           0.9978063945212478,
           1,
           0.9328765945632177,
           0.8582692314450578,
           0.938796897652004,
           0.6790478005724585,
           0.7621314001411675,
           0.991224121713605,
           0.9949050340850846,
           -0.39877875623890924
          ],
          [
           0.38188312962464477,
           0.33903331149236665,
           0.13152453890928784,
           0.9274253826568852,
           0.7376535095353034,
           0.7984524462689733,
           0.9367169117551478,
           0.9328765945632176,
           1,
           0.8660123268251445,
           0.9639881829267938,
           0.7098899197132912,
           0.7914193393879022,
           0.9395453796016779,
           0.9358193918316419,
           -0.38447637050607314
          ],
          [
           0.5563515123859162,
           0.5473200590841563,
           0.5364858694767576,
           0.962596733179032,
           0.7037495480222489,
           0.751285887440661,
           0.8651423238514424,
           0.8582692314450577,
           0.8660123268251445,
           1,
           0.9071276618401125,
           0.6786624871139461,
           0.7447429859701542,
           0.8807520284946829,
           0.8910974925640105,
           -0.14322556039510198
          ],
          [
           0.3487487076374941,
           0.3203965352301583,
           0.17216592885556128,
           0.9111475170492642,
           0.6362989086685518,
           0.7244485841419488,
           0.9375184671839226,
           0.9387968976520041,
           0.9639881829267938,
           0.9071276618401126,
           0.9999999999999999,
           0.5956872110568207,
           0.7075950236392606,
           0.9396794177256076,
           0.9490165428865026,
           -0.40598106389959887
          ],
          [
           0.7402125319644001,
           0.6992338468349271,
           0.40094535571188034,
           0.7744145041398566,
           0.993954185727047,
           0.9380792965918817,
           0.6930623830954393,
           0.6790478005724585,
           0.7098899197132912,
           0.6786624871139461,
           0.5956872110568208,
           1,
           0.9719683951636716,
           0.6977146327677869,
           0.6771547207966677,
           0.045436400432705595
          ],
          [
           0.6569422411252949,
           0.6118462879024481,
           0.33487134448468864,
           0.8210524945332096,
           0.9863802647365706,
           0.9807847284076574,
           0.7728802314687855,
           0.7621314001411676,
           0.7914193393879022,
           0.7447429859701542,
           0.7075950236392606,
           0.9719683951636716,
           0.9999999999999999,
           0.7751198015929881,
           0.7599858630032778,
           -0.12804970179912284
          ],
          [
           0.45878982177395355,
           0.42950313862274075,
           0.2427745663262212,
           0.916331182376748,
           0.7324947421319666,
           0.7973863424970653,
           0.9970874898103477,
           0.991224121713605,
           0.9395453796016778,
           0.8807520284946829,
           0.9396794177256076,
           0.6977146327677868,
           0.775119801592988,
           1,
           0.994632224236154,
           -0.36047151998352955
          ],
          [
           0.48152185889055094,
           0.4532269788486554,
           0.2613741202431961,
           0.920077845565032,
           0.7128581331445778,
           0.7813797870054365,
           0.9950106215451961,
           0.9949050340850846,
           0.9358193918316419,
           0.8910974925640106,
           0.9490165428865025,
           0.6771547207966677,
           0.7599858630032776,
           0.994632224236154,
           1,
           -0.3728581887246097
          ],
          [
           0.34626007333890885,
           0.3983333401572341,
           0.5015520373215445,
           -0.14826609459177872,
           -0.02625436681532069,
           -0.21551249095816888,
           -0.38330558504857704,
           -0.3987787562389092,
           -0.38447637050607314,
           -0.14322556039510198,
           -0.40598106389959887,
           0.045436400432705595,
           -0.12804970179912284,
           -0.3604715199835296,
           -0.3728581887246097,
           1
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmax": 1,
         "cmin": -1,
         "colorbar": {
          "title": {
           "text": "Correlation"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ],
         "showscale": false
        },
        "height": 1000,
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Correlation matrix between metrics"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "ticktext": [
          "Euclidean distance between cheese and decision square",
          "Taxicab distance between cheese and decision square",
          "Steps between cheese and decision square",
          "Steps between cheese and top right square",
          "Euclidean distance between cheese and top right square",
          "Taxicab distance between cheese and top right square",
          "Euclidean distance between decision square and top right square",
          "Taxicab distance between decision square and top right square",
          "Steps between decision square and top right square",
          "Steps between cheese and top-right 5x5",
          "Steps between decision square and top-right 5x5",
          "Euclidean distance between cheese and top-right 5x5",
          "Taxicab distance between cheese and top-right 5x5",
          "Euclidean distance between decision square and top-right 5x5",
          "Taxicab distance between decision square and top-right 5x5",
          "Norm of cheese coordinate"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "ticktext": [
          "Euclidean distance between cheese and decision square",
          "Taxicab distance between cheese and decision square",
          "Steps between cheese and decision square",
          "Steps between cheese and top right square",
          "Euclidean distance between cheese and top right square",
          "Taxicab distance between cheese and top right square",
          "Euclidean distance between decision square and top right square",
          "Taxicab distance between decision square and top right square",
          "Steps between decision square and top right square",
          "Steps between cheese and top-right 5x5",
          "Steps between decision square and top-right 5x5",
          "Euclidean distance between cheese and top-right 5x5",
          "Taxicab distance between cheese and top-right 5x5",
          "Euclidean distance between decision square and top-right 5x5",
          "Taxicab distance between decision square and top-right 5x5",
          "Norm of cheese coordinate"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ],
         "title": {
          "text": ""
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the correlation matrix in plotly\n",
    "final_metrics = [\"euc_dist_cheese_decision_square\"]\n",
    "\n",
    "correlations = np.zeros((len(recorded_metrics), len(recorded_metrics)))\n",
    "for i, metric1 in enumerate(recorded_metrics.keys()):\n",
    "    for j, metric2 in enumerate(recorded_metrics.keys()):\n",
    "        correlations[i, j] = np.corrcoef(\n",
    "            recorded_metrics[metric1], recorded_metrics[metric2]\n",
    "        )[0, 1]\n",
    "\n",
    "# Show the correlation matrix in plotly, with a colorbar\n",
    "# On mouse over, show the name of each metric\n",
    "corrmap = px.imshow(\n",
    "    correlations,\n",
    "    labels=dict(x=\"Metric 1\", y=\"Metric 2\", color=\"Correlation\"),\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    zmin=-1,\n",
    "    zmax=1,\n",
    ")\n",
    "# Hover template: show the name of each metric, by looking up its value in the x and y lists\n",
    "corrmap.update_traces(hovertemplate=\"(%{x}, %{y}) = %{z:.3f} <extra></extra>\")\n",
    "\n",
    "corrmap.update_layout(title_text=\"Correlation matrix between metrics\")\n",
    "# Don't show numbers over each cell\n",
    "corrmap.update_traces(text=None)\n",
    "# Show x and y axis labels\n",
    "corrmap.update_xaxes(\n",
    "    ticktext=list(map(english_attr, recorded_metrics.keys())),\n",
    "    tickvals=list(range(len(recorded_metrics.keys()))),\n",
    ")\n",
    "\n",
    "corrmap.update_yaxes(\n",
    "    ticktext=list(map(english_attr, recorded_metrics.keys())),\n",
    "    tickvals=list(range(len(recorded_metrics.keys()))),\n",
    ")\n",
    "\n",
    "# Hide x and y axis titles\n",
    "corrmap.update_xaxes(title_text=\"\")\n",
    "corrmap.update_yaxes(title_text=\"\")\n",
    "\n",
    "# Hide the color bar\n",
    "corrmap.update_layout(coloraxis_showscale=False)\n",
    "\n",
    "# Make size of plot a bit bigger\n",
    "corrmap.update_layout(width=1000, height=1000)\n",
    "corrmap.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41d1c538",
   "metadata": {},
   "source": [
    "And here are the strongest correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8514cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+-------------+---------------------------------------------------------------+\n",
      "|                             \u001b[1mMetric 1\u001b[0m                            | \u001b[1mCorrelation\u001b[0m |                            \u001b[1mMetric 2\u001b[0m                           |\n",
      "+-----------------------------------------------------------------+-------------+---------------------------------------------------------------+\n",
      "| Euclidean distance between decision square and top right square |    0.998    | Taxicab distance between decision square and top right square |\n",
      "| Euclidean distance between decision square and top right square |    0.997    |  \u001b[1mEuclidean distance between decision square and top-right 5x5\u001b[0m |\n",
      "| Euclidean distance between decision square and top right square |    0.995    |   Taxicab distance between decision square and top-right 5x5  |\n",
      "|  Taxicab distance between decision square and top right square  |    0.995    |   Taxicab distance between decision square and top-right 5x5  |\n",
      "|   \u001b[1mEuclidean distance between decision square and top-right 5x5\u001b[0m  |    0.995    |   Taxicab distance between decision square and top-right 5x5  |\n",
      "|      \u001b[1mEuclidean distance between cheese and top right square\u001b[0m     |    0.994    |      Euclidean distance between cheese and top-right 5x5      |\n",
      "|  Taxicab distance between decision square and top right square  |    0.991    |  \u001b[1mEuclidean distance between decision square and top-right 5x5\u001b[0m |\n",
      "|      \u001b[1mEuclidean distance between cheese and top right square\u001b[0m     |    0.986    |       Taxicab distance between cheese and top-right 5x5       |\n",
      "|       Taxicab distance between cheese and top right square      |    0.981    |       Taxicab distance between cheese and top-right 5x5       |\n",
      "|      \u001b[1mEuclidean distance between cheese and decision square\u001b[0m      |    0.975    |      Taxicab distance between cheese and decision square      |\n",
      "|       Euclidean distance between cheese and top-right 5x5       |    0.972    |       Taxicab distance between cheese and top-right 5x5       |\n",
      "|      \u001b[1mEuclidean distance between cheese and top right square\u001b[0m     |    0.969    |      Taxicab distance between cheese and top right square     |\n",
      "|        Steps between decision square and top right square       |    0.964    |        Steps between decision square and top-right 5x5        |\n",
      "|            Steps between cheese and top right square            |    0.963    |             Steps between cheese and top-right 5x5            |\n",
      "|         Steps between decision square and top-right 5x5         |    0.949    |   Taxicab distance between decision square and top-right 5x5  |\n",
      "|         Steps between decision square and top-right 5x5         |    0.940    |  \u001b[1mEuclidean distance between decision square and top-right 5x5\u001b[0m |\n",
      "|        Steps between decision square and top right square       |    0.940    |  \u001b[1mEuclidean distance between decision square and top-right 5x5\u001b[0m |\n",
      "|  Taxicab distance between decision square and top right square  |    0.939    |        Steps between decision square and top-right 5x5        |\n",
      "|       Taxicab distance between cheese and top right square      |    0.938    |      Euclidean distance between cheese and top-right 5x5      |\n",
      "| Euclidean distance between decision square and top right square |    0.938    |        Steps between decision square and top-right 5x5        |\n",
      "| Euclidean distance between decision square and top right square |    0.937    |       Steps between decision square and top right square      |\n",
      "|        Steps between decision square and top right square       |    0.936    |   Taxicab distance between decision square and top-right 5x5  |\n",
      "|  Taxicab distance between decision square and top right square  |    0.933    |       Steps between decision square and top right square      |\n",
      "|            Steps between cheese and top right square            |    0.927    |       Steps between decision square and top right square      |\n",
      "|            Steps between cheese and top right square            |    0.920    |   Taxicab distance between decision square and top-right 5x5  |\n",
      "+-----------------------------------------------------------------+-------------+---------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Get the top k absolute value correlations, ignoring diagonals\n",
    "k = 50\n",
    "len_diagonal = len(correlations)\n",
    "topk = np.argsort(np.abs(correlations).flatten())[-(k + len_diagonal) :][\n",
    "    ::-1\n",
    "]  # Diagonal will be 1, so just add in len_diagonal\n",
    "\n",
    "# Print the top k correlations in a pretty table\n",
    "table = prettytable.PrettyTable()\n",
    "table.field_names = map(bold_text, [\"Metric 1\", \"Correlation\", \"Metric 2\"])\n",
    "\n",
    "for i in topk:\n",
    "    # Get the row and column of the correlation\n",
    "    row, col = i // len(correlations), i % len(correlations)\n",
    "    # Ignore the diagonal and the lower triangle\n",
    "    if row >= col:\n",
    "        continue\n",
    "    # Get the metric names\n",
    "    metric1, metric2 = (\n",
    "        list(recorded_metrics.keys())[row],\n",
    "        list(recorded_metrics.keys())[col],\n",
    "    )\n",
    "    # Add the row to the table\n",
    "    table.add_row(\n",
    "        [\n",
    "            format_attr(metric1),\n",
    "            f\"{correlations[row, col]:.3f}\",\n",
    "            format_attr(metric2),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e51004a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(attrs: List[str], data_frame: pd.DataFrame):\n",
    "    \"\"\"Runs a LASSO-regularized regression on the data using the given attributes. Returns the clf.\"\"\"\n",
    "    assert len(attrs) > 0, \"Must have at least one attribute to regress upon\"\n",
    "    for attr in attrs:\n",
    "        assert attr in data_frame, f\"Attribute {attr} not in data frame\"\n",
    "    assert \"cheese\" in data_frame, \"Attribute 'cheese' not in data frame\"\n",
    "\n",
    "    x = data_frame[attrs]\n",
    "    y = np.ravel(data_frame[[\"cheese\"]])\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        random_state=0, solver=\"liblinear\", penalty=\"l1\"\n",
    "    ).fit(x, y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def compute_avg_accuracy(\n",
    "    attrs: List[str], data_frame: pd.DataFrame, num_runs: int\n",
    ") -> float:\n",
    "    \"\"\"Runs a LASSO-regularized regression num_runs times on the data using the given attributes. Returns the average accuracy.\"\"\"\n",
    "    assert len(attrs) > 0, \"Must have at least one attribute to regress upon\"\n",
    "    assert num_runs > 0, \"Must run at least one time\"\n",
    "\n",
    "    accuracies = []\n",
    "    for i in range(num_runs):\n",
    "        train, test = train_test_split(data_frame, test_size=0.2)\n",
    "        clf = run_regression(attrs, train)\n",
    "        accuracies.append(clf.score(test[attrs], test[\"cheese\"]))\n",
    "    return np.mean(accuracies)\n",
    "\n",
    "\n",
    "def display_coeff_table(clf: Any, attrs: List[str]):\n",
    "    \"\"\"Displays the coefficients for each attribute, printing the label next to each coefficient.\"\"\"\n",
    "    assert len(attrs) > 0, \"Must have at least one attribute\"\n",
    "\n",
    "    # Print the coefficient for each attribute, printing the label next to each coefficient\n",
    "    table = prettytable.PrettyTable()\n",
    "    table.field_names = [bold_text(\"Attribute\"), bold_text(\"Coefficient\")]\n",
    "    for i, attr in enumerate(attrs):\n",
    "        table.add_row([format_attr(attr), f\"{clf.coef_[0][i]:.3f}\"])\n",
    "\n",
    "    # Add a row for the intercept\n",
    "    table.add_row([\"Intercept\", f\"{clf.intercept_[0]:.3f}\"])\n",
    "    print(table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5bf611e",
   "metadata": {},
   "source": [
    "# Using maze features to predict whether the mouse got the cheese "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f3f5156",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_runs):\n\u001b[1;32m     35\u001b[0m     train, test \u001b[39m=\u001b[39m train_test_split(df, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m     clf \u001b[39m=\u001b[39m run_regression(attributes, train)\n\u001b[1;32m     38\u001b[0m     avg_coefficients[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[1;32m     39\u001b[0m         clf\u001b[39m.\u001b[39mcoef_[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m avg_coefficients[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m     )  \u001b[39m# Update all but last entry with coeffs\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     avg_coefficients[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mintercept_[\u001b[39m0\u001b[39m]  \u001b[39m# Last entry is the intercept\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m, in \u001b[0;36mrun_regression\u001b[0;34m(attrs, data_frame)\u001b[0m\n\u001b[1;32m      8\u001b[0m x \u001b[39m=\u001b[39m data_frame[attrs]\n\u001b[1;32m      9\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mravel(data_frame[[\u001b[39m\"\u001b[39m\u001b[39mcheese\u001b[39m\u001b[39m\"\u001b[39m]])\n\u001b[1;32m     11\u001b[0m clf \u001b[39m=\u001b[39m LogisticRegression(\n\u001b[1;32m     12\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, solver\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, penalty\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39ml1\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m---> 13\u001b[0m )\u001b[39m.\u001b[39;49mfit(x, y)\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m clf\n",
      "File \u001b[0;32m~eale/miniconda3/envs/MATS/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1216\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[39mif\u001b[39;00m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1211\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1212\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m > 1 does not have any effect when\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is set to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs))\n\u001b[1;32m   1215\u001b[0m         )\n\u001b[0;32m-> 1216\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _fit_liblinear(\n\u001b[1;32m   1217\u001b[0m         X,\n\u001b[1;32m   1218\u001b[0m         y,\n\u001b[1;32m   1219\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m   1220\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1221\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintercept_scaling,\n\u001b[1;32m   1222\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1223\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty,\n\u001b[1;32m   1224\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual,\n\u001b[1;32m   1225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1226\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1227\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1228\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1229\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1230\u001b[0m     )\n\u001b[1;32m   1231\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   1233\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39msag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~eale/miniconda3/envs/MATS/lib/python3.10/site-packages/sklearn/svm/_base.py:1181\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     classes_ \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m   1180\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(classes_) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1181\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1182\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1183\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1184\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1185\u001b[0m             \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1186\u001b[0m         )\n\u001b[1;32m   1188\u001b[0m     class_weight_ \u001b[39m=\u001b[39m compute_class_weight(class_weight, classes\u001b[39m=\u001b[39mclasses_, y\u001b[39m=\u001b[39my)\n\u001b[1;32m   1189\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: False"
     ]
    }
   ],
   "source": [
    "keys = list(recorded_metrics.keys())\n",
    "data = {key: recorded_metrics[key] for key in keys}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = stats.zscore(\n",
    "    df\n",
    ")  # zscore standardizes the data by subtracting the mean and dividing by the standard deviation\n",
    "\n",
    "# Now we want to add the cheese column to the dataframe\n",
    "df[\"cheese\"] = pd.DataFrame(\n",
    "    {\"cheese\": [(runs[i].got_cheese) for i in range(len(runs))]}\n",
    ")\n",
    "\n",
    "# Choose which keys to regress upon\n",
    "attributes = [\n",
    "    \"steps_between_cheese_5x5\",\n",
    "    \"euc_dist_cheese_5x5\",\n",
    "    \"steps_between_decision_square_5x5\",\n",
    "    \"euc_dist_decision_square_5x5\",\n",
    "    \"steps_between_cheese_top_right\",\n",
    "    \"euc_dist_cheese_top_right\",\n",
    "    \"steps_between_decision_square_top_right\",\n",
    "    \"euc_dist_decision_square_top_right\",\n",
    "    \"steps_between_cheese_decision_square\",\n",
    "    \"euc_dist_cheese_decision_square\",\n",
    "    \"cheese_coord_norm\",\n",
    "]\n",
    "\n",
    "n_runs = 50\n",
    "\n",
    "avg_accuracy = 0\n",
    "avg_coefficients = np.zeros(len(attributes) + 1)  # Add one for the intercept\n",
    "# We reduce variance in the score by running the regression multiple times\n",
    "for x in range(n_runs):\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "    clf = run_regression(attributes, train)\n",
    "    avg_coefficients[:-1] = (\n",
    "        clf.coef_[0] + avg_coefficients[:-1]\n",
    "    )  # Update all but last entry with coeffs\n",
    "    avg_coefficients[-1] += clf.intercept_[0]  # Last entry is the intercept\n",
    "\n",
    "    x = test[attributes]\n",
    "    y = np.ravel(test[[\"cheese\"]])\n",
    "    avg_accuracy += clf.score(x, y)\n",
    "\n",
    "avg_accuracy /= n_runs\n",
    "avg_coefficients /= n_runs\n",
    "# Print the coefficient for each attribute, printing the label next to each coefficient (for the last run)\n",
    "display_coeff_table(clf, attributes)\n",
    "# print(avg_coefficients / n_runs) # TODO show what avg coefficients are\n",
    "print(\n",
    "    f\"The average regression accuracy is {avg_accuracy:.3f}, averaged over\"\n",
    "    f\" {n_runs} regressions.\"\n",
    ")\n",
    "\n",
    "# Record the sign of the coefficients for each attribute\n",
    "regression_coeff_signs = {\n",
    "    attr: clf.coef_[0][i] > 0\n",
    "    for i, attr in enumerate(attributes)\n",
    "    if attr in claimed_attributes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheese_rate = sum(df[\"cheese\"]) / len(df[\"cheese\"])\n",
    "max_baseline = max(\n",
    "    cheese_rate, 1 - cheese_rate\n",
    ")  # Always predict \"cheese\" or \"no cheese\"\n",
    "print(\n",
    "    'Accuracy of the trivial \"always yes\" or \"always no\" predictor:'\n",
    "    f\" {max_baseline:.3f}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19678d56",
   "metadata": {},
   "source": [
    "Let's examine whether it's predictively useful to know the Euclidean\n",
    "distance between the cheese and the decision square, given that we\n",
    "already know the step distance. (Spoiler: It is!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_lists = [\n",
    "    [\"steps_between_cheese_decision_square\"],\n",
    "    [\n",
    "        \"steps_between_cheese_decision_square\",\n",
    "        \"euc_dist_cheese_decision_square\",\n",
    "    ],\n",
    "]\n",
    "n_regressions = 100\n",
    "\n",
    "for attr_list in attr_lists:\n",
    "    print()\n",
    "    clf = run_regression(attr_list, df)\n",
    "    display_coeff_table(clf, attr_list)\n",
    "    print(\n",
    "        \"The accuracy for these attributes is\"\n",
    "        f\" {compute_avg_accuracy(attr_list, df, n_regressions):.3f}, averaged\"\n",
    "        f\" over {n_regressions} regressions.\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33762c04",
   "metadata": {},
   "source": [
    "# Stress-testing our results\n",
    "Overall, the features we claimed to be important, still seem to be important, although to different strengths. The claimed attributes don't exhibit sign-flips in a range of conditions.\n",
    "\n",
    "## Trying to re-pinpoint the claimed features\n",
    "Peli Grietzer originally found the bolded attributes using the following methodology, which he describes as follows:\n",
    "\n",
    "> I did multiple logistic regression with all the factors at once, then did a multiple logistic regression with all-factors-except-x for each x and wrote down which factors caused test accuracy loss when dropped.\n",
    ">\n",
    "> Four factors caused non-trivial test accuracy loss, so I took those four factors and did a multiple logistic regression on these four factors, and saw that the test accuracy was as good as with all factors.\n",
    ">\n",
    "> I then tested dropping each of the four factors and using just three, and saw that there was a non-trivial drop in test accuracy for each of them.\n",
    ">\n",
    "> I then tested adding one additional factor to the four factors, trying every unused factor and seeing no increase in test accuracy.\n",
    "\n",
    "This section implements that methodology. This doesn't seem to replicate, which is some evidence against our initial results -- there's less of a reason to pick out the four attributes we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fda0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a multiple logistic regression with all-attributes-except-x for each x and store which attributes caused test accuracy loss when dropped.\n",
    "relative_drop = 0.005\n",
    "accuracy_drop_attrs = []\n",
    "num_runs = 5\n",
    "\n",
    "for attr in recorded_metrics.keys():\n",
    "    attr_accuracy = compute_avg_accuracy(\n",
    "        list(recorded_metrics.keys() - {attr}), df, num_runs\n",
    "    )\n",
    "    if attr_accuracy < avg_accuracy * (1 - relative_drop):\n",
    "        accuracy_drop_attrs.append(attr)\n",
    "\n",
    "print(\n",
    "    f\"When excluded, the following attributes caused a >{relative_drop*100}%\"\n",
    "    \" relative drop in accuracy:\"\n",
    ")\n",
    "for attr in accuracy_drop_attrs:\n",
    "    print(f\"\\t{format_attr(attr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take these attributes and run a multiple logistic regression on these attributes, and check that the test accuracy was as good as with all attributes.\n",
    "if len(accuracy_drop_attrs) > 0:\n",
    "    new_accuracy = compute_avg_accuracy(accuracy_drop_attrs, df, num_runs=10)\n",
    "    print(\n",
    "        \"The accuracy of the regression with the dropped attributes is\"\n",
    "        f\" {new_accuracy:.3f}.\"\n",
    "    )\n",
    "    if new_accuracy < avg_accuracy * (1 - relative_drop):\n",
    "        print(\n",
    "            \"Accuracy of regression with dropped attributes is not as good as\"\n",
    "            \" with all attributes.\"\n",
    "        )\n",
    "\n",
    "    # Try dropping each of the attributes that caused a drop in accuracy and verify that the accuracy drops significantly\n",
    "    for attr in accuracy_drop_attrs:\n",
    "        attr_accuracy = compute_avg_accuracy(\n",
    "            list(recorded_metrics.keys() - {attr}), df, num_runs=1\n",
    "        )\n",
    "        if attr_accuracy > avg_accuracy * (1 - relative_drop):\n",
    "            print(\n",
    "                f\"The accuracy of the regression with ({format_attr(attr)})\"\n",
    "                \" dropped is not significantly lower than with all attributes\"\n",
    "                f\" ({avg_accuracy:.3f}).\"\n",
    "            )\n",
    "    print()\n",
    "\n",
    "    # Try adding each of the attributes that did not cause a drop in accuracy and see if the accuracy increases significantly\n",
    "    for attr in list(recorded_metrics.keys() - set(accuracy_drop_attrs)):\n",
    "        attr_accuracy = compute_avg_accuracy(\n",
    "            list(recorded_metrics.keys() | {attr}), df, num_runs=1\n",
    "        )\n",
    "        if attr_accuracy > avg_accuracy * (1 - relative_drop):\n",
    "            print(\n",
    "                f\"The accuracy of the regression with ({format_attr(attr)})\"\n",
    "                \" added is not significantly higher than with all attributes.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "claimed_accuracy = compute_avg_accuracy(claimed_attributes, df, num_runs=10)\n",
    "clf = run_regression(claimed_attributes, df)\n",
    "display_coeff_table(clf, claimed_attributes)\n",
    "print(\n",
    "    f\"Claimed attributes obtain accuracy of {claimed_accuracy:.3f}, which is\"\n",
    "    f\" {(avg_accuracy - claimed_accuracy)*100:.3f} absolute percent less than\"\n",
    "    \" when all features are used.\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "116e6e4c",
   "metadata": {},
   "source": [
    "## Robustness to regressing on random subsets of attributes\n",
    "\n",
    "When regressing on related factors (e.g. Euclidean and step distance to cheese from decision square), we might wonder: \"Did these coefficients only come out this way as a fluke of the regression itself?\". For example, factor subset X may induce feature $a$ to have a positive coefficient, while a different factor subset Y induces $a$ with a negative regression coefficient. Encouragingly, the signs of our claimed attributes are highly robust to which set of factors we regress upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subset_regression(\n",
    "    data_frame: pd.DataFrame, n_attrs: int, verbose: bool = False\n",
    ") -> Tuple[Any, List[str]]:\n",
    "    \"\"\"Runs a regression on the data frame using a random subset of n_attrs attributes. Returns the clf and the attributes used.\"\"\"\n",
    "    attrs = random.sample(list(recorded_metrics.keys() - {\"cheese\"}), n_attrs)\n",
    "    clf = run_regression(attrs, train)\n",
    "\n",
    "    if verbose:\n",
    "        display_coeff_table(clf, attrs)\n",
    "\n",
    "    return clf, attrs\n",
    "\n",
    "\n",
    "def check_claimed_signs(\n",
    "    clf: Any, attrs: List[str], data_frame: pd.DataFrame, verbose: bool = False\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"Checks if the signs of the regression coefficients for the given attributes match regression_coeff_signs. Returns a dictionary which counts the number of times each attribute had the wrong sign.\"\"\"\n",
    "    counters = defaultdict(int)\n",
    "\n",
    "    for i, attr in enumerate(attrs):\n",
    "        if attr not in regression_coeff_signs.keys() or attr in counters:\n",
    "            continue\n",
    "        assert attr in data_frame, f\"Attribute {attr} not in data frame\"\n",
    "        if (clf.coef_[0][i] >= 0) != regression_coeff_signs[attr]:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Attribute {attr} has incorrect sign; expected\"\n",
    "                    f\" {regression_coeff_signs[attr]} but got\"\n",
    "                    f\" {clf.coef_[0][i] >= 0}\"\n",
    "                )\n",
    "                display_coeff_table(clf, attrs)\n",
    "            counters[\n",
    "                attr\n",
    "            ] += 1  # Increment the attribute that had the incorrect sign\n",
    "    return counters\n",
    "\n",
    "\n",
    "# Run the regression multiple times and check the signs\n",
    "# See distribution of sign errors over multiple runs\n",
    "counter = {attr: 0 for attr in claimed_attributes}\n",
    "n_rand_runs = 200\n",
    "for x in range(n_rand_runs):\n",
    "    # Draw a random number of attributes to use\n",
    "    n_attrs = random.randint(1, len(recorded_metrics.keys()) - 1)\n",
    "    clf, attrs = run_subset_regression(train, n_attrs)\n",
    "    new_counter = check_claimed_signs(clf, attrs, train, verbose=False)\n",
    "    for key in new_counter.keys():\n",
    "        counter[key] += new_counter[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96cd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a table displaying the percentage of times each attribute had the wrong sign\n",
    "sign_table = prettytable.PrettyTable()\n",
    "sign_table.field_names = [\"Attribute\", \"% of runs with flipped sign\"]\n",
    "for key in counter.keys():\n",
    "    sign_table.add_row([english_attr(key), counter[key] / n_rand_runs * 100])\n",
    "print(sign_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83f3df78",
   "metadata": {},
   "source": [
    "## Variation inflation factor (VIF)\n",
    "As I (Alex) understand it, VIF measures how much of the variance of the regression coefficients are due to multicollinearity. Restricting our attention to the features mentioned in the post, the VIF scores are medium-high (but tolerable), while including all features leads to extremely high VIF. This is some weak further evidence that our regression was not a statistical fluke or modeling decision (but I'm not a statistician!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute VIF (variance inflation factor) for each attribute\n",
    "# This is a measure of how much the variance of the coefficient is inflated due to multicollinearity\n",
    "# Above 5 is usually considered to be a sign of that\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Ignore runtime warnings due to division by 0 from R2=1\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for attrs in [claimed_attributes, recorded_metrics.keys()]:\n",
    "    print()\n",
    "    print(\n",
    "        \"VIF for claimed attributes\"\n",
    "        if attrs == claimed_attributes\n",
    "        else \"VIF for all attributes\"\n",
    "    )\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Features\"] = df[attrs].columns\n",
    "    vif[\"VIF\"] = [\n",
    "        variance_inflation_factor(df[attrs].values, i)\n",
    "        for i in range(df[attrs].shape[1])\n",
    "    ]\n",
    "\n",
    "    print(vif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c77f2f46953a93e2cdf30c808e94602375d16ad6294e549473c1f301bc8b554"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
